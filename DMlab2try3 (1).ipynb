{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VdXf3LtU480Y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Yz3E8MQXj2q_"
      },
      "outputs": [],
      "source": [
        "# 載入數據\n",
        "df_identity = pd.read_csv('/content/data_identification.csv')\n",
        "df_emotion = pd.read_csv('/content/emotion.csv')\n",
        "df_tweet = pd.read_json('/content/tweets_DM.json',lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VHkyTI_sVkK",
        "outputId": "2c25869d-ef2a-4b0c-a8d7-ba257704bafa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                             _source\n",
            "0  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...\n",
            "1  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...\n",
            "2  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...\n",
            "3  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...\n",
            "4  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...\n"
          ]
        }
      ],
      "source": [
        "df_tweet_source = df_tweet[['_source']]\n",
        "print(df_tweet_source.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7kSBUrYsjtF",
        "outputId": "48321e01-aebc-4126-9f69-a9aba633aaaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       _source_split\n",
            "0  [{'tweet': {'hashtags': ['Snapchat'],  'tweet_...\n",
            "1  [{'tweet': {'hashtags': ['freepress',  'TrumpL...\n",
            "2  [{'tweet': {'hashtags': ['bibleverse'],  'twee...\n",
            "3  [{'tweet': {'hashtags': [],  'tweet_id': '0x1c...\n",
            "4  [{'tweet': {'hashtags': [],  'tweet_id': '0x2d...\n"
          ]
        }
      ],
      "source": [
        "df_tweet['_source_str'] = df_tweet['_source'].apply(str)\n",
        "df_tweet['_source_split'] = df_tweet['_source_str'].apply(lambda x: x.split(','))\n",
        "print(df_tweet[['_source_split']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3eo9AolsmqZ",
        "outputId": "8fa72235-3622-42ae-a9a6-9c8a9d861927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      _source_cleaned\n",
            "0    'tweet_id': '0x376b20', 'text': 'People who p...\n",
            "1    'TrumpLegacy', 'CNN'], 'tweet_id': '0x2d5350'...\n",
            "2    'tweet_id': '0x28b412', 'text': 'Confident of...\n",
            "3    'tweet_id': '0x1cd5b0', 'text': 'Now ISSA is ...\n",
            "4    'tweet_id': '0x2de201', 'text': '\"Trust is no...\n",
            "5    'LaughOutLoud'], 'tweet_id': '0x1d755c', 'tex...\n",
            "6    'tweet_id': '0x2c91a8', 'text': 'Still waitin...\n",
            "7    'tweet_id': '0x368e95', 'text': 'Love knows n...\n",
            "8    'tweet_id': '0x249c0c', 'text': '@DStvNgCare ...\n",
            "9    'money', 'possessions'], 'tweet_id': '0x21844...\n",
            "10   'gender', 'diversity'], 'tweet_id': '0x359db9...\n",
            "11   'tweet_id': '0x23b037', 'text': \"I love suffe...\n",
            "12   'tweet_id': '0x1fde89', 'text': 'Can someone ...\n",
            "13   'ecology'], 'tweet_id': '0x37a0a9', 'text': '...\n",
            "14   'tweet_id': '0x269112', 'text': \"My brother d...\n",
            "15   'tweet_id': '0x360665', 'text': 'On a scale o...\n",
            "16   'evatech', 'bendingcomposite', 'inovarsandton...\n",
            "17   'tweet_id': '0x25be54', 'text': 'Vomi post bi...\n",
            "18   'tweet_id': '0x33832f', 'text': 'One of my dr...\n",
            "19   'tweet_id': '0x2e0b03', 'text': 'Thankful for...\n"
          ]
        }
      ],
      "source": [
        "df_tweet['_source_cleaned'] = df_tweet['_source_str'].apply(lambda x: x.split(',', 1)[-1] if ',' in x else x)\n",
        "print(df_tweet[['_source_cleaned']].head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvtjD1v5s2ko",
        "outputId": "87212805-b294-4241-b4dc-28d93ac292ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                     _source_cleaned\n",
            "0  'tweet_id': '0x376b20', 'text': 'People who po...\n",
            "1  'tweet_id': '0x2d5350', 'text': '@brianklaas A...\n",
            "2  'tweet_id': '0x28b412', 'text': 'Confident of ...\n",
            "3  'tweet_id': '0x1cd5b0', 'text': 'Now ISSA is s...\n",
            "4  'tweet_id': '0x2de201', 'text': '\"Trust is not...\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def extract_tweet_info(source_str):\n",
        "    # Regular expression to find 'tweet_id' and 'text' and their values\n",
        "    tweet_id_match = re.search(r\"'tweet_id':\\s*'([^']*)'\", source_str)\n",
        "    text_match = re.search(r\"'text':\\s*'([^']*)'\", source_str)\n",
        "\n",
        "    # Extract 'tweet_id' and 'text' if found\n",
        "    tweet_id = tweet_id_match.group(0) if tweet_id_match else None\n",
        "    text = text_match.group(0) if text_match else None\n",
        "\n",
        "    # Combine the results (only if both are found)\n",
        "    return ', '.join(filter(None, [tweet_id, text]))\n",
        "\n",
        "# Apply the function to the '_source' column\n",
        "df_tweet['_source_cleaned'] = df_tweet['_source_str'].apply(extract_tweet_info)\n",
        "\n",
        "# Display the first few rows with the cleaned data\n",
        "print(df_tweet[['_source_cleaned']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJO8gLO1s5V_",
        "outputId": "1b011de3-7ebb-45fb-fbd4-19d0f8f27a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   tweet_id                                               text\n",
            "0  0x376b20  People who post \"add me on #Snapchat\" must be ...\n",
            "1  0x2d5350  @brianklaas As we see, Trump is dangerous to #...\n",
            "2  0x28b412  Confident of your obedience, I write to you, k...\n",
            "3  0x1cd5b0                Now ISSA is stalking Tasha 😂😂😂 <LH>\n",
            "4  0x2de201  \"Trust is not the same as faith. A friend is s...\n"
          ]
        }
      ],
      "source": [
        "# Extract tweet_id and text into separate columns using regular expressions\n",
        "df_tweet['tweet_id'] = df_tweet['_source_cleaned'].apply(lambda x: re.search(r\"'tweet_id':\\s*'([^']*)'\", x).group(1) if re.search(r\"'tweet_id':\\s*'([^']*)'\", x) else None)\n",
        "df_tweet['text'] = df_tweet['_source_cleaned'].apply(lambda x: re.search(r\"'text':\\s*'([^']*)'\", x).group(1) if re.search(r\"'text':\\s*'([^']*)'\", x) else None)\n",
        "df_tweet = df_tweet.drop(columns=['_source'])\n",
        "\n",
        "# Display the first few rows to verify the result\n",
        "print(df_tweet[['tweet_id', 'text']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AHCP8LHfj6Zb"
      },
      "outputs": [],
      "source": [
        "# merge the datasets\n",
        "df_identity['tweet_id'] = df_identity['tweet_id'].str.strip()\n",
        "df_emotion['tweet_id'] = df_emotion['tweet_id'].str.strip()\n",
        "df_tweet['tweet_id'] = df_tweet['tweet_id'].str.strip()\n",
        "df_merged = pd.merge(df_identity, df_emotion, on='tweet_id', how='outer')\n",
        "df_merged = pd.merge(df_merged, df_tweet, on='tweet_id', how='outer')\n",
        "\n",
        "df_train = df_merged[df_merged['identification'] == 'train']\n",
        "df_test = df_merged[df_merged['identification'] == 'test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "wcM6SaWwj8-h"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary columns\n",
        "columns_to_drop = ['_crawldate', '_index', '_type', '_source_str', '_source_split', '_source_cleaned']\n",
        "df_train = df_train.drop(columns=columns_to_drop, axis=1)\n",
        "df_test = df_test.drop(columns=columns_to_drop, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HdkEKW92j_wq"
      },
      "outputs": [],
      "source": [
        "# clean NaN\n",
        "df_train['text'] = df_train['text'].fillna(\"\")\n",
        "df_test['text'] = df_test['text'].fillna(\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDkWHaT3kGbe",
        "outputId": "fff88e15-d45b-484a-8caa-7d50daa97486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_test shape: (411972, 5000)\n",
            "Y_train shape: (1455563,)\n",
            "X_train shape: (1455563, 5000)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "# 1. TF-IDF for feature extraction\n",
        "BOW_vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=3,\n",
        "    max_df=0.7\n",
        ")\n",
        "\n",
        "BOW_vectorizer.fit(df_train['text'])\n",
        "X_train = BOW_vectorizer.transform(df_train['text'])\n",
        "X_test = BOW_vectorizer.transform(df_test['text'])\n",
        "\n",
        "# 2. convert the label\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(df_train['emotion'])\n",
        "\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"Y_train shape: {y_train.shape}\")\n",
        "print(f\"X_train shape: {X_train.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(max_iter=1000, solver='saga', penalty='elasticnet', l1_ratio=0.5, n_jobs=-1)\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "P2O-tXM7QHwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "try:\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error during prediction:\", e)\n",
        "    print(\"Ignoring problematic rows.\")\n",
        "\n",
        "    # exclude the data that casue error\n",
        "    valid_indices = np.array([i for i in range(X_test.shape[0]) if i not in problematic_indices])\n",
        "\n",
        "    y_pred = clf.predict(X_test[valid_indices])\n",
        "\n",
        "y_pred_classes = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "df_test['predicted_emotion'] = y_pred_classes\n",
        "df_test.to_csv('test_predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "JqrziGehpKBG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.read_csv('test_predictions.csv')\n",
        "print(df_pred.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNCdZTN_Q1rV",
        "outputId": "991d4efe-9465-44fb-8e45-a891bb299b62"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   tweet_id identification  emotion  _score  \\\n",
            "0  0x1c7f0f           test      NaN      62   \n",
            "1  0x1c7f12           test      NaN     756   \n",
            "2  0x1c7f13           test      NaN     213   \n",
            "3  0x1c7f17           test      NaN     603   \n",
            "4  0x1c7f18           test      NaN     609   \n",
            "\n",
            "                                                text predicted_emotion  \n",
            "0                                                NaN               joy  \n",
            "1                                                NaN               joy  \n",
            "2  The only “big plan” you ever had in your life,...               joy  \n",
            "3  Looking back on situations old & new, recent o...      anticipation  \n",
            "4  @jasoninthehouse Why do you insist on talking ...           sadness  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('test_predictions.csv')\n",
        "\n",
        "# keep the 'tweet_id' and 'predicted_emotion' only\n",
        "df_pred = df[['tweet_id', 'predicted_emotion']]\n",
        "\n",
        "# change column name\n",
        "df_pred.columns = ['id', 'emotion']\n",
        "\n",
        "\n",
        "df_pred.to_csv('test_predictions_reduced.csv', index=False)\n",
        "\n",
        "\n",
        "print(df_pred.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVXv1FDyRy9y",
        "outputId": "dadded07-9246-40db-b949-cfd4cffd77de"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         id       emotion\n",
            "0  0x1c7f0f           joy\n",
            "1  0x1c7f12           joy\n",
            "2  0x1c7f13           joy\n",
            "3  0x1c7f17  anticipation\n",
            "4  0x1c7f18       sadness\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}